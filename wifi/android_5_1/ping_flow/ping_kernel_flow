dhd_linux.c
->  {
        dhd_pub_t * dhd_attach(osl_t *osh, struct dhd_bus *bus, uint bus_hdrlen
#ifdef BCMDBUS
                , void *data
#endif
                )
        {
            if (dhd->rxthread_enabled) {
                bzero(&dhd->pub.skbbuf[0], sizeof(void *) * MAXSKBPEND);
                /* Initialize RXF thread */
                PROC_START(dhd_rxf_thread, dhd, &dhd->thr_rxf_ctl, 0, "dhd_rxf");
                if (dhd->thr_rxf_ctl.thr_pid < 0) {
                    goto fail;
                }
            }

        }

        static int dhd_rxf_thread(void *data)
        {
            while (1) {
                if (down_interruptible(&tsk->sema) == 0) {
                    skb = dhd_rxf_dequeue(pub);
        
                    while (skb) {
                        void *skbnext = PKTNEXT(pub->osh, skb);
                        PKTSETNEXT(pub->osh, skb, NULL);
                        bcm_object_trace_opr(skb, BCM_OBJDBG_REMOVE,
                                __FUNCTION__, __LINE__);
#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 0)
                        netif_rx_ni(skb);
#else
                        netif_rx(skb);
                        local_irq_save(flags);
                        RAISE_RX_SOFTIRQ();
                        local_irq_restore(flags);

#endif
                        skb = skbnext;
                    }
                }
            }
        }
    }
----------------------------------------------------------------------------------
Dev.c (net\core)
->  {
        static struct pernet_operations __net_initdata netdev_net_ops = {
            .init = netdev_init,
            .exit = netdev_exit,
        };

        /*
         *       This is called single threaded during boot, so no need
         *       to take the rtnl semaphore.
         */
        static int __init net_dev_init(void)
        {
            dev_proc_init();

            netdev_kobject_init();

            INIT_LIST_HEAD(&ptype_all);
            for (i = 0; i < PTYPE_HASH_SIZE; i++)
                INIT_LIST_HEAD(&ptype_base[i]);

            INIT_LIST_HEAD(&offload_base);

            register_pernet_subsys(&netdev_net_ops);

            /*
             *	Initialise the packet receive queues.
             */

            for_each_possible_cpu(i) {                                  // 为每个CPU添加接收队列处理函数
                struct softnet_data *sd = &per_cpu(softnet_data, i);

                memset(sd, 0, sizeof(*sd));
                skb_queue_head_init(&sd->input_pkt_queue);
                skb_queue_head_init(&sd->process_queue);
                sd->completion_queue = NULL;
                INIT_LIST_HEAD(&sd->poll_list);
                sd->output_queue = NULL;
                sd->output_queue_tailp = &sd->output_queue;
#ifdef CONFIG_RPS
                sd->csd.func = rps_trigger_softirq;
                sd->csd.info = sd;
                sd->csd.flags = 0;
                sd->cpu = i;
#endif

                sd->backlog.poll = process_backlog;                     // 接收队列处理函数process_backlog
                sd->backlog.weight = weight_p;                          // int weight_p __read_mostly = 64;            /* old backlog weight */
                sd->backlog.gro_list = NULL;
                sd->backlog.gro_count = 0;
            }


            /* The loopback device is special if any other network devices
             * is present in a network namespace the loopback device must
             * be present. Since we now dynamically allocate and free the
             * loopback device ensure this invariant is maintained by
             * keeping the loopback device as the first device on the
             * list of network devices.  Ensuring the loopback devices
             * is the first device that appears and the last network device
             * that disappears.
             */
            register_pernet_device(&loopback_net_ops);

            register_pernet_device(&default_device_ops);

            open_softirq(NET_TX_SOFTIRQ, net_tx_action);                // 当触发tx_softirq的时候就会调用net_tx_action
            open_softirq(NET_RX_SOFTIRQ, net_rx_action);                // 当触发rx_softirq的时候就会调用net_rx_action

            hotcpu_notifier(dev_cpu_callback, 0);
            dst_init();
        }

        int netif_rx_ni(struct sk_buff *skb)
        {
            int err;

            preempt_disable();
            err = netif_rx(skb);
            if (local_softirq_pending())
                do_softirq();                                           // 调用net_rx_action
            preempt_enable();

            return err;
        }

        /**
         *	netif_rx	-	post buffer to the network code
         *	@skb: buffer to post
         *
         *	This function receives a packet from a device driver and queues it for
         *	the upper (protocol) levels to process.  It always succeeds. The buffer
         *	may be dropped during processing for congestion control or by the
         *	protocol layers.
         *
         *	return values:
         *	NET_RX_SUCCESS	(no congestion)
         *	NET_RX_DROP     (packet was dropped)
         *
         */

        int netif_rx(struct sk_buff *skb)
        {
            int ret;

            /* if netpoll wants it, pretend we never saw it */
            if (netpoll_rx(skb))
                return NET_RX_DROP;

            net_timestamp_check(netdev_tstamp_prequeue, skb);

            trace_netif_rx(skb);
        #ifdef CONFIG_RPS
            if (static_key_false(&rps_needed)) {
                struct rps_dev_flow voidflow, *rflow = &voidflow;
                int cpu;

                preempt_disable();
                rcu_read_lock();

                cpu = get_rps_cpu(skb->dev, skb, &rflow);
                if (cpu < 0)
                    cpu = smp_processor_id();

                ret = enqueue_to_backlog(skb, cpu, &rflow->last_qtail);

                rcu_read_unlock();
                preempt_enable();
            } else
        #endif
            {
                unsigned int qtail;
                ret = enqueue_to_backlog(skb, get_cpu(), &qtail);           // 将skb添加到backlog队列
                put_cpu();
            }
            return ret;
        }

        int netdev_max_backlog __read_mostly = 1000;

        /*
         * enqueue_to_backlog is called to queue an skb to a per CPU backlog
         * queue (may be a remote CPU queue).
         */
        static int enqueue_to_backlog(struct sk_buff *skb, int cpu,
                unsigned int *qtail)
        {
            if (skb_queue_len(&sd->input_pkt_queue) <= netdev_max_backlog) {
                if (skb_queue_len(&sd->input_pkt_queue)) {                          // 2, 第二步才走这里
        enqueue:
                    printk("enqueue_to_backlog skb_queue_len\n");
                    __skb_queue_tail(&sd->input_pkt_queue, skb);
                    input_queue_tail_incr_save(sd, qtail);
                    rps_unlock(sd);
                    local_irq_restore(flags);
                    return NET_RX_SUCCESS;
                }

                /* Schedule NAPI for backlog device
                 * We can use non atomic operation since we own the queue lock
                 */
                printk("enqueue_to_backlog = %d\n", sd->backlog.state);
                if (!__test_and_set_bit(NAPI_STATE_SCHED, &sd->backlog.state)) {    // 1, 从log打印来看是先走的这里，置位NAPI_STATE_SCHED
                    if (!rps_ipi_queued(sd))
                        ____napi_schedule(sd, &sd->backlog);
                }
                goto enqueue;
            }
        }

        static void net_rx_action(struct softirq_action *h)
        {
            while (!list_empty(&sd->poll_list)) {
                /* This NAPI_STATE_SCHED test is for avoiding a race
                 * with netpoll's poll_napi().  Only the entity which
                 * obtains the lock and sees NAPI_STATE_SCHED set will
                 * actually make the ->poll() call.  Therefore we avoid
                 * accidentally calling ->poll() when NAPI is not scheduled.
                 */
                work = 0;
                if (test_bit(NAPI_STATE_SCHED, &n->state)) {        // 3, 判断NAPI_STATE_SCHED是否置位，如果是，执行poll，即上面的process_backlog
                    printk("net_rx_action n->poll\n");
                    work = n->poll(n, weight);
                    trace_napi_poll(n);
                }
            }
        }

        static int process_backlog(struct napi_struct *napi, int quota)
        {
            __netif_receive_skb(skb);
        }

        static int __netif_receive_skb(struct sk_buff *skb)
        {
            int ret;

            if (sk_memalloc_socks() && skb_pfmemalloc(skb)) {
                unsigned long pflags = current->flags;

                /*
                 * PFMEMALLOC skbs are special, they should
                 * - be delivered to SOCK_MEMALLOC sockets only
                 * - stay away from userspace
                 * - have bounded memory usage
                 *
                 * Use PF_MEMALLOC as this saves us from propagating the allocation
                 * context down to all allocation sites.
                 */
                current->flags |= PF_MEMALLOC;
                ret = __netif_receive_skb_core(skb, true);
                tsk_restore_flags(current, pflags, PF_MEMALLOC);
            } else
                ret = __netif_receive_skb_core(skb, false);

            return ret;
        }

        static int __netif_receive_skb_core(struct sk_buff *skb, bool pfmemalloc)
        {
            /* deliver only exact match when indicated */
            null_or_dev = deliver_exact ? skb->dev : NULL;

            type = skb->protocol;
            list_for_each_entry_rcu(ptype,
                    &ptype_base[ntohs(type) & PTYPE_HASH_MASK], list) {
                if (ptype->type == type &&
                        (ptype->dev == null_or_dev || ptype->dev == skb->dev ||
                         ptype->dev == orig_dev)) {
                    if (pt_prev)
                        ret = deliver_skb(skb, pt_prev, orig_dev);
                    pt_prev = ptype;
                }
            }

            if (pt_prev) {
                printk("__netif_receive_skb_core pt_prev = %0x\n", be16_to_cpu(pt_prev->type));     // 跑iperf或者ping都是0x0800 
                if (unlikely(skb_orphan_frags(skb, GFP_ATOMIC)))                                    // 802.1X(0x888E), ARP(0x0806)
                    goto drop;
                else
                    ret = pt_prev->func(skb, skb->dev, pt_prev, orig_dev);                          // 调用对应的func，如果是0x800,则对应ETH_P_IP
            }                                                                                       // func即为ip_rcv
        }
    }
------------------------------------------------------------------------------
Af_inet.c (net\ipv4)
->  {
        struct proto tcp_prot = {
        .name			= "TCP",
        .owner			= THIS_MODULE,
        .close			= tcp_close,
        .connect		= tcp_v4_connect,
        .disconnect		= tcp_disconnect,
        .accept			= inet_csk_accept,
        .ioctl			= tcp_ioctl,
        .init			= tcp_v4_init_sock,
        .destroy		= tcp_v4_destroy_sock,
        .shutdown		= tcp_shutdown,
        .setsockopt		= tcp_setsockopt,
        .getsockopt		= tcp_getsockopt,
        .recvmsg		= tcp_recvmsg,
        .sendmsg		= tcp_sendmsg,
        .sendpage		= tcp_sendpage,
        .backlog_rcv		= tcp_v4_do_rcv,
        .release_cb		= tcp_release_cb,
        .hash			= inet_hash,
        .unhash			= inet_unhash,
        .get_port		= inet_csk_get_port,
        .enter_memory_pressure	= tcp_enter_memory_pressure,
        .sockets_allocated	= &tcp_sockets_allocated,
        .orphan_count		= &tcp_orphan_count,
        .memory_allocated	= &tcp_memory_allocated,
        .memory_pressure	= &tcp_memory_pressure,
        .sysctl_wmem		= sysctl_tcp_wmem,
        .sysctl_rmem		= sysctl_tcp_rmem,
        .max_header		= MAX_TCP_HEADER,
        .obj_size		= sizeof(struct tcp_sock),
        .slab_flags		= SLAB_DESTROY_BY_RCU,
        .twsk_prot		= &tcp_timewait_sock_ops,
        .rsk_prot		= &tcp_request_sock_ops,
        .h.hashinfo		= &tcp_hashinfo,
        .no_autobind		= true,
#ifdef CONFIG_COMPAT
        .compat_setsockopt	= compat_tcp_setsockopt,
        .compat_getsockopt	= compat_tcp_getsockopt,
#endif
#ifdef CONFIG_MEMCG_KMEM
        .init_cgroup		= tcp_init_cgroup,
        .destroy_cgroup		= tcp_destroy_cgroup,
        .proto_cgroup		= tcp_proto_cgroup,
#endif
        };

        struct proto udp_prot = {
            .name		   = "UDP",
            .owner		   = THIS_MODULE,
            .close		   = udp_lib_close,
            .connect	   = ip4_datagram_connect,
            .disconnect	   = udp_disconnect,
            .ioctl		   = udp_ioctl,
            .destroy	   = udp_destroy_sock,
            .setsockopt	   = udp_setsockopt,
            .getsockopt	   = udp_getsockopt,
            .sendmsg	   = udp_sendmsg,
            .recvmsg	   = udp_recvmsg,
            .sendpage	   = udp_sendpage,
            .backlog_rcv	   = __udp_queue_rcv_skb,
            .release_cb	   = ip4_datagram_release_cb,
            .hash		   = udp_lib_hash,
            .unhash		   = udp_lib_unhash,
            .rehash		   = udp_v4_rehash,
            .get_port	   = udp_v4_get_port,
            .memory_allocated  = &udp_memory_allocated,
            .sysctl_mem	   = sysctl_udp_mem,
            .sysctl_wmem	   = &sysctl_udp_wmem_min,
            .sysctl_rmem	   = &sysctl_udp_rmem_min,
            .obj_size	   = sizeof(struct udp_sock),
            .slab_flags	   = SLAB_DESTROY_BY_RCU,
            .h.udp_table	   = &udp_table,
#ifdef CONFIG_COMPAT
            .compat_setsockopt = compat_udp_setsockopt,
            .compat_getsockopt = compat_udp_getsockopt,
#endif
            .clear_sk	   = sk_prot_clear_portaddr_nulls,
        };

        struct proto raw_prot = {
            .name		   = "RAW",
            .owner		   = THIS_MODULE,
            .close		   = raw_close,
            .destroy	   = raw_destroy,
            .connect	   = ip4_datagram_connect,
            .disconnect	   = udp_disconnect,
            .ioctl		   = raw_ioctl,
            .init		   = raw_init,
            .setsockopt	   = raw_setsockopt,
            .getsockopt	   = raw_getsockopt,
            .sendmsg	   = raw_sendmsg,
            .recvmsg	   = raw_recvmsg,
            .bind		   = raw_bind,
            .backlog_rcv	   = raw_rcv_skb,
            .release_cb	   = ip4_datagram_release_cb,
            .hash		   = raw_hash_sk,
            .unhash		   = raw_unhash_sk,
            .obj_size	   = sizeof(struct raw_sock),
            .h.raw_hash	   = &raw_v4_hashinfo,
#ifdef CONFIG_COMPAT
            .compat_setsockopt = compat_raw_setsockopt,
            .compat_getsockopt = compat_raw_getsockopt,
            .compat_ioctl	   = compat_raw_ioctl,
#endif
        };

        struct proto ping_prot = {
            .name =		"PING",
            .owner =	THIS_MODULE,
            .init =		ping_init_sock,
            .close =	ping_close,
            .connect =	ip4_datagram_connect,
            .disconnect =	udp_disconnect,
            .setsockopt =	ip_setsockopt,
            .getsockopt =	ip_getsockopt,
            .sendmsg =	ping_v4_sendmsg,
            .recvmsg =	ping_recvmsg,
            .bind =		ping_bind,
            .backlog_rcv =	ping_queue_rcv_skb,
            .release_cb =	ip4_datagram_release_cb,
            .hash =		ping_hash,
            .unhash =	ping_unhash,
            .get_port =	ping_get_port,
            .obj_size =	sizeof(struct inet_sock),
        };

        static const struct net_proto_family inet_family_ops = {
            .family = PF_INET,
            .create = inet_create,
            .owner	= THIS_MODULE,
        };

        static const struct net_protocol icmp_protocol = {
            .handler =	icmp_rcv,
            .err_handler =	icmp_err,
            .no_policy =	1,
            .netns_ok =	1,
        };

        static const struct net_protocol udp_protocol = {
            .handler =	udp_rcv,
            .err_handler =	udp_err,
            .no_policy =	1,
            .netns_ok =	1,
        };

        static const struct net_protocol tcp_protocol = {
            .early_demux	=	tcp_v4_early_demux,
            .handler	=	tcp_v4_rcv,
            .err_handler	=	tcp_v4_err,
            .no_policy	=	1,
            .netns_ok	=	1,
        };

        #ifdef CONFIG_IP_MULTICAST
        static const struct net_protocol igmp_protocol = {
            .handler =	igmp_rcv,
            .netns_ok =	1,
        };
        #endif
        
        /* Upon startup we insert all the elements in inetsw_array[] into
         * the linked list inetsw.
         */
        static struct inet_protosw inetsw_array[] =
        {
            {
                .type =       SOCK_STREAM,
                .protocol =   IPPROTO_TCP,
                .prot =       &tcp_prot,
                .ops =        &inet_stream_ops,
                .no_check =   0,
                .flags =      INET_PROTOSW_PERMANENT |
                    INET_PROTOSW_ICSK,
            },

            {
                .type =       SOCK_DGRAM,
                .protocol =   IPPROTO_UDP,
                .prot =       &udp_prot,
                .ops =        &inet_dgram_ops,
                .no_check =   UDP_CSUM_DEFAULT,
                .flags =      INET_PROTOSW_PERMANENT,
            },

            {
                .type =       SOCK_DGRAM,
                .protocol =   IPPROTO_ICMP,
                .prot =       &ping_prot,
                .ops =        &inet_dgram_ops,
                .no_check =   UDP_CSUM_DEFAULT,
                .flags =      INET_PROTOSW_REUSE,
            },

            {
                .type =       SOCK_RAW,
                .protocol =   IPPROTO_IP,	/* wild card */
                .prot =       &raw_prot,
                .ops =        &inet_sockraw_ops,
                .no_check =   UDP_CSUM_DEFAULT,
                .flags =      INET_PROTOSW_REUSE,
            }
        };

        static struct packet_type ip_packet_type __read_mostly = {
            .type = cpu_to_be16(ETH_P_IP),                          // #define ETH_P_IP	0x0800		/* Internet Protocol packet	*/
            .func = ip_rcv,
        };

        static int __init inet_init(void)
        {
            rc = proto_register(&tcp_prot, 1);

            rc = proto_register(&udp_prot, 1);

            rc = proto_register(&raw_prot, 1);

            rc = proto_register(&ping_prot, 1);

            (void)sock_register(&inet_family_ops);

        #ifdef CONFIG_SYSCTL
            ip_static_sysctl_init();
        #endif

            inet_add_protocol(&icmp_protocol, IPPROTO_ICMP);
            inet_add_protocol(&udp_protocol, IPPROTO_UDP);
            inet_add_protocol(&tcp_protocol, IPPROTO_TCP);
        #ifdef CONFIG_IP_MULTICAST
            inet_add_protocol(&igmp_protocol, IPPROTO_IGMP);
        #endif
        
            /* Register the socket-side information for inet_create. */
            for (r = &inetsw[0]; r < &inetsw[SOCK_MAX]; ++r)
                INIT_LIST_HEAD(r);

            for (q = inetsw_array; q < &inetsw_array[INETSW_ARRAY_LEN]; ++q)
                inet_register_protosw(q);
        
            /*
             *	Set the ARP module up
             */

            arp_init();

            /*
             *	Set the IP module up
             */

            ip_init();

            tcp_v4_init();

            /* Setup TCP slab cache for open requests. */
            tcp_init();

            /* Setup UDP memory threshold */
            udp_init();

            /* Add UDP-Lite (RFC 3828) */
            udplite4_register();

            ping_init();

            /*
             *	Set the ICMP layer up
             */

            if (icmp_init() < 0)
                panic("Failed to create the ICMP control socket.\n");

            /*
             *	Initialise the multicast router
             */
#if defined(CONFIG_IP_MROUTE)
            if (ip_mr_init())
                pr_crit("%s: Cannot init ipv4 mroute\n", __func__);
#endif
            /*
             *	Initialise per-cpu ipv4 mibs
             */

            if (init_ipv4_mibs())
                pr_crit("%s: Cannot init ipv4 mibs\n", __func__);

            ipv4_proc_init();

            ipfrag_init();

            dev_add_pack(&ip_packet_type);
        }
    }
----------------------------------------------------------------------------------------------------------
Protocol.c (net\ipv4)
->  {
        int inet_add_protocol(const struct net_protocol *prot, unsigned char protocol)
        {
            if (!prot->netns_ok) {
                pr_err("Protocol %u is not namespace aware, cannot register.\n",
                        protocol);
                return -EINVAL;
            }

            return !cmpxchg((const struct net_protocol **)&inet_protos[protocol],           // 将protocol添加到inet_protos数组里面
                    NULL, prot) ? 0 : -1;
        }
    }
---------------------------------------------------------------------------------------------------------
Ip_input.c (net\ipv4)
->  {
        /*
         * 	Main IP Receive routine.
         */
        int ip_rcv(struct sk_buff *skb, struct net_device *dev, struct packet_type *pt, struct net_device *orig_dev)
        {
            return NF_HOOK(NFPROTO_IPV4, NF_INET_PRE_ROUTING, skb, dev, NULL,
                    ip_rcv_finish);
        }

        static int ip_rcv_finish(struct sk_buff *skb)
        {
            if (!skb_dst(skb)) {
                int err = ip_route_input_noref(skb, iph->daddr, iph->saddr,
                        iph->tos, skb->dev);
                if (unlikely(err)) {
                    if (err == -EXDEV)
                        NET_INC_STATS_BH(dev_net(skb->dev),
                                LINUX_MIB_IPRPFILTER);
                    goto drop;
                }
            }

            if (iph->ihl > 5 && ip_rcv_options(skb))
                goto drop;

            rt = skb_rtable(skb);
            if (rt->rt_type == RTN_MULTICAST) {
                IP_UPD_PO_STATS_BH(dev_net(rt->dst.dev), IPSTATS_MIB_INMCAST,
                        skb->len);
            } else if (rt->rt_type == RTN_BROADCAST)
                IP_UPD_PO_STATS_BH(dev_net(rt->dst.dev), IPSTATS_MIB_INBCAST,
                        skb->len);

            return dst_input(skb);                                              
        }
    }
------------------------------------------------------------------------------------
Dst.h (include\net)
->  {
        /* Input packet from network to transport.  */
        static inline int dst_input(struct sk_buff *skb)
        {
            printk("dst_input Enter\n");
            return skb_dst(skb)->input(skb);            // ip_route_input_noref会确定input对应什么函数，比如ping，对应的是ip_local_deliver
        }
    }
------------------------------------------------------------------------------------
Route.c (net\ipv4)
->  {
        int ip_route_input_noref(struct sk_buff *skb, __be32 daddr, __be32 saddr,
                u8 tos, struct net_device *dev)
        {
            res = ip_route_input_slow(skb, daddr, saddr, tos, dev);
        }

        /*
         *	NOTE. We drop all the packets that has local source
         *	addresses, because every properly looped back packet
         *	must have correct destination already attached by output routine.
         *
         *	Such approach solves two big problems:
         *	1. Not simplex devices are handled properly.
         *	2. IP spoofing attempts are filtered with 100% of guarantee.
         *	called with rcu_read_lock()
         */

        static int ip_route_input_slow(struct sk_buff *skb, __be32 daddr, __be32 saddr,
                u8 tos, struct net_device *dev)
        {
            printk("ip_route_input_slow res.type = %d\n", res.type);

            if (res.type == RTN_BROADCAST)
                goto brd_input;

            if (res.type == RTN_LOCAL) {                                // ping走这里
                err = fib_validate_source(skb, saddr, daddr, tos,
                        LOOPBACK_IFINDEX,
                        dev, in_dev, &itag);
                if (err < 0)
                    goto martian_source_keep_err;
                goto local_input;                                       // 跳转到local_input
            }

            if (!IN_DEV_FORWARD(in_dev))
                goto no_route;
            if (res.type != RTN_UNICAST)
                goto martian_destination;

            err = ip_mkroute_input(skb, &res, &fl4, in_dev, daddr, saddr, tos);     //这里如果是ping的话暂时不会走！！！

        brd_input:
            printk("ip_route_input_slow brd_input\n");
            if (skb->protocol != htons(ETH_P_IP))
                goto e_inval;

            if (!ipv4_is_zeronet(saddr)) {
                err = fib_validate_source(skb, saddr, 0, tos, 0, dev,
                        in_dev, &itag);
                if (err < 0)
                    goto martian_source_keep_err;
            }
            flags |= RTCF_BROADCAST;
            res.type = RTN_BROADCAST;
            RT_CACHE_STAT_INC(in_brd);

        local_input:
            rth->dst.input= ip_local_deliver;                       // dst.input = ip_local_deliver
            rth->dst.output= ip_rt_bug;                             // dst.output= ip_rt_bug, 后面会被重新赋值替换掉！！
            rth->rt_genid = rt_genid(net);
            rth->rt_flags 	= flags|RTCF_LOCAL;
            rth->rt_type	= res.type;
            rth->rt_is_input = 1;
            rth->rt_iif	= 0;
            rth->rt_pmtu	= 0;
            rth->rt_gateway	= 0;
            rth->rt_uses_gateway = 0;
            INIT_LIST_HEAD(&rth->rt_uncached);
            RT_CACHE_STAT_INC(in_slow_tot);
            if (res.type == RTN_UNREACHABLE) {
                rth->dst.input= ip_error;
                rth->dst.error= -err;
                rth->rt_flags 	&= ~RTCF_LOCAL;
            }
            if (do_cache) {
                if (unlikely(!rt_cache_route(&FIB_RES_NH(res), rth))) {
                    rth->dst.flags |= DST_NOCACHE;
                    rt_add_uncached_list(rth);
                }
            }
            skb_dst_set(skb, &rth->dst);
            err = 0;
            goto out;
        }
    }
--------------------------------------------------------------------------------------
Ip_input.c (net\ipv4)
->  {
        /*
         * 	Deliver IP Packets to the higher protocol layers.
         */
        int ip_local_deliver(struct sk_buff *skb)
        {
            /*
             *	Reassemble IP fragments.
             */

            if (ip_is_fragment(ip_hdr(skb))) {
                if (ip_defrag(skb, IP_DEFRAG_LOCAL_DELIVER))
                    return 0;
            }

            return NF_HOOK(NFPROTO_IPV4, NF_INET_LOCAL_IN, skb, skb->dev, NULL,
                    ip_local_deliver_finish);
        }

        static int ip_local_deliver_finish(struct sk_buff *skb)
        {
            int protocol = ip_hdr(skb)->protocol;
            const struct net_protocol *ipprot;

    	resubmit:
            raw = raw_local_deliver(skb, protocol);

            ipprot = rcu_dereference(inet_protos[protocol]);    // 这里就会找到protocol对应的inet_protos数组
            if (ipprot != NULL) {
                int ret;

                if (!ipprot->no_policy) {
                    if (!xfrm4_policy_check(NULL, XFRM_POLICY_IN, skb)) {
                        kfree_skb(skb);
                        goto out;
                    }
                    nf_reset(skb);
                }
                ret = ipprot->handler(skb);                     // 调用protocol对应的handler结构体，比如ping，即IPPROTO_ICMP对应的是icmp_protocol
                if (ret < 0) {
                    protocol = -ret;
                    goto resubmit;
                }
                IP_INC_STATS_BH(net, IPSTATS_MIB_INDELIVERS);
            }
        }
    }
--------------------------------------------------------------------------------------
Icmp.c (net\ipv4)
->  {
        /*
         *	This table is the definition of how we handle ICMP.
         */
        static const struct icmp_control icmp_pointers[NR_ICMP_TYPES + 1] = {
            [ICMP_ECHOREPLY] = {
                .handler = ping_rcv,
            },
            [1] = {
                .handler = icmp_discard,
                .error = 1,
            },
            [2] = {
                .handler = icmp_discard,
                .error = 1,
            },
            [ICMP_DEST_UNREACH] = {
                .handler = icmp_unreach,
                .error = 1,
            },
            [ICMP_SOURCE_QUENCH] = {
                .handler = icmp_unreach,
                .error = 1,
            },
            [ICMP_REDIRECT] = {
                .handler = icmp_redirect,
                .error = 1,
            },
            [6] = {
                .handler = icmp_discard,
                .error = 1,
            },
            [7] = {
                .handler = icmp_discard,
                .error = 1,
            },
            [ICMP_ECHO] = {
                .handler = icmp_echo,
            },
            [9] = {
                .handler = icmp_discard,
                .error = 1,
            },
            [10] = {
                .handler = icmp_discard,
                .error = 1,
            },
            [ICMP_TIME_EXCEEDED] = {
                .handler = icmp_unreach,
                .error = 1,
            },
            [ICMP_PARAMETERPROB] = {
                .handler = icmp_unreach,
                .error = 1,
            },
            [ICMP_TIMESTAMP] = {
                .handler = icmp_timestamp,
            },
            [ICMP_TIMESTAMPREPLY] = {
                .handler = icmp_discard,
            },
            [ICMP_INFO_REQUEST] = {
                .handler = icmp_discard,
            },
            [ICMP_INFO_REPLY] = {
                .handler = icmp_discard,
            },
            [ICMP_ADDRESS] = {
                .handler = icmp_discard,
            },
            [ICMP_ADDRESSREPLY] = {
                .handler = icmp_discard,
            },
        };

        /*
         *	Deal with incoming ICMP packets.
         */
        int icmp_rcv(struct sk_buff *skb)
        {
            /*
             *	Parse the ICMP message
             */

            if (rt->rt_flags & (RTCF_BROADCAST | RTCF_MULTICAST)) {
                /*
                 *	RFC 1122: 3.2.2.6 An ICMP_ECHO to broadcast MAY be
                 *	  silently ignored (we let user decide with a sysctl).
                 *	RFC 1122: 3.2.2.8 An ICMP_TIMESTAMP MAY be silently
                 *	  discarded if to broadcast/multicast.
                 */
                if ((icmph->type == ICMP_ECHO ||
                            icmph->type == ICMP_TIMESTAMP) &&
                        net->ipv4.sysctl_icmp_echo_ignore_broadcasts) {
                    goto error;
                }
                if (icmph->type != ICMP_ECHO &&
                        icmph->type != ICMP_TIMESTAMP &&
                        icmph->type != ICMP_ADDRESS &&
                        icmph->type != ICMP_ADDRESSREPLY) {
                    goto error;
                }
            }

            icmp_pointers[icmph->type].handler(skb);
        }

        /*
         *	Handle ICMP_ECHO ("ping") requests.
         *
         *	RFC 1122: 3.2.2.6 MUST have an echo server that answers ICMP echo
         *		  requests.
         *	RFC 1122: 3.2.2.6 Data received in the ICMP_ECHO request MUST be
         *		  included in the reply.
         *	RFC 1812: 4.3.3.6 SHOULD have a config option for silently ignoring
         *		  echo requests, MUST have default=NOT.
         *	See also WRT handling of options once they are done and working.
         */

        static void icmp_echo(struct sk_buff *skb)                      // 如果是ping request，则对应ICMP_ECHO, 即icmp_echo
        {
            struct net *net;

            net = dev_net(skb_dst(skb)->dev);
            if (!net->ipv4.sysctl_icmp_echo_ignore_all) {
                struct icmp_bxm icmp_param;

                icmp_param.data.icmph	   = *icmp_hdr(skb);
                icmp_param.data.icmph.type = ICMP_ECHOREPLY;
                icmp_param.skb		   = skb;
                icmp_param.offset	   = 0;
                icmp_param.data_len	   = skb->len;
                icmp_param.head_len	   = sizeof(struct icmphdr);
                icmp_reply(&icmp_param, skb);
            }
        }
        
        /*
         *	Driving logic for building and sending ICMP messages.
         */

        static void icmp_reply(struct icmp_bxm *icmp_param, struct sk_buff *skb)
        {
            printk("icmp_reply Enter\n");

            printk("icmp_reply ip_route_output_key\n");
            rt = ip_route_output_key(net, &fl4);            // ip_route_output_key会确定output对应什么函数，比如ping，对应的是ip_output

            if (icmpv4_xrlim_allow(net, rt, &fl4, icmp_param->data.icmph.type,
                        icmp_param->data.icmph.code)) {
                printk("icmp_reply icmpv4_xrlim_allow\n");
                icmp_push_reply(icmp_param, &fl4, &ipc, &rt);
            }
            ip_rt_put(rt);
        }

        static void icmp_push_reply(struct icmp_bxm *icmp_param,
			    struct flowi4 *fl4,
			    struct ipcm_cookie *ipc, struct rtable **rt)
        {
            printk("icmp_push_reply ip_push_pending_frames\n");
            ip_push_pending_frames(sk, fl4);
        }

        int ip_push_pending_frames(struct sock *sk, struct flowi4 *fl4)
        {
            struct sk_buff *skb;

            skb = ip_finish_skb(sk, fl4);
            if (!skb)
                return 0;

            printk("ip_push_pending_frames Enter\n");
            /* Netfilter gets whole the not fragmented skb. */
            return ip_send_skb(sock_net(sk), skb);
        }
    }
--------------------------------------------------------------------------------------
Route.h (include\net)
->  {
        static inline struct rtable *ip_route_output_key(struct net *net, struct flowi4 *flp)
        {
            return ip_route_output_flow(net, flp, NULL);
        }
    }
-------------------------------------------------------------------------------------
Route.c (net\ipv4)
->  {
        struct rtable *ip_route_output_flow(struct net *net, struct flowi4 *flp4,
				    struct sock *sk)
        {
            struct rtable *rt = __ip_route_output_key(net, flp4);

            if (IS_ERR(rt))
                return rt;

            if (flp4->flowi4_proto)
                rt = (struct rtable *) xfrm_lookup(net, &rt->dst,
                        flowi4_to_flowi(flp4),
                        sk, 0);

            return rt;
        }

        /*
         * Major route resolver routine.
         */
        struct rtable *__ip_route_output_key(struct net *net, struct flowi4 *fl4)
        {
            printk("__ip_route_output_key Enter\n");

            printk("__ip_route_output_key res.type = %d\n", res.type);              // ping是RTN_UNICAST

        make_route:
            printk("__ip_route_output_key make_route\n");
            rth = __mkroute_output(&res, fl4, orig_oif, dev_out, flags);
        }

        /* called with rcu_read_lock() */
        static struct rtable *__mkroute_output(const struct fib_result *res,
                const struct flowi4 *fl4, int orig_oif,
                struct net_device *dev_out,
                unsigned int flags)
        {
            printk("__mkroute_output Enter\n");

        add:
            rth = rt_dst_alloc(dev_out,
                    IN_DEV_CONF_GET(in_dev, NOPOLICY),
                    IN_DEV_CONF_GET(in_dev, NOXFRM),
                    do_cache);
            if (!rth)
                return ERR_PTR(-ENOBUFS);

            printk("__mkroute_output add\n");
            rth->dst.output = ip_output;                        // 这里对dst.output重新赋值为 ip_output

            rth->rt_genid = rt_genid(dev_net(dev_out));
            rth->rt_flags	= flags;
            rth->rt_type	= type;
            rth->rt_is_input = 0;
            rth->rt_iif	= orig_oif ? : 0;
            rth->rt_pmtu	= 0;
            rth->rt_gateway = 0;
            rth->rt_uses_gateway = 0;
            INIT_LIST_HEAD(&rth->rt_uncached);

            RT_CACHE_STAT_INC(out_slow_tot);

            printk("__mkroute_output flags = %x\n", flags);
            if (flags & RTCF_LOCAL)
                rth->dst.input = ip_local_deliver;
            if (flags & (RTCF_BROADCAST | RTCF_MULTICAST)) {
                if (flags & RTCF_LOCAL &&
                        !(dev_out->flags & IFF_LOOPBACK)) {
                    rth->dst.output = ip_mc_output;
                    RT_CACHE_STAT_INC(out_slow_mc);
                }
            }
        }
    }
-------------------------------------------------------------------------------------
Ip_output.c (net\ipv4)
->  {
        int ip_send_skb(struct net *net, struct sk_buff *skb)
        {
            int err;

            err = ip_local_out(skb);
            if (err) {
                if (err > 0)
                    err = net_xmit_errno(err);
                if (err)
                    IP_INC_STATS(net, IPSTATS_MIB_OUTDISCARDS);
            }

            return err;
        }

        int __ip_local_out(struct sk_buff *skb)
        {
            struct iphdr *iph = ip_hdr(skb);

            iph->tot_len = htons(skb->len);
            ip_send_check(iph);
            printk("__ip_local_out Enter\n");
            return nf_hook(NFPROTO_IPV4, NF_INET_LOCAL_OUT, skb, NULL,
                    skb_dst(skb)->dev, dst_output);
        }

        int ip_local_out(struct sk_buff *skb)
        {
            int err;

            printk("ip_local_out Enter\n");
            err = __ip_local_out(skb);
            if (likely(err == 1))
                err = dst_output(skb);

            return err;
        }

        int ip_output(struct sk_buff *skb)
        {
            struct net_device *dev = skb_dst(skb)->dev;

            IP_UPD_PO_STATS(dev_net(dev), IPSTATS_MIB_OUT, skb->len);

            skb->dev = dev;
            skb->protocol = htons(ETH_P_IP);

            return NF_HOOK_COND(NFPROTO_IPV4, NF_INET_POST_ROUTING, skb, NULL, dev,
                    ip_finish_output,
                    !(IPCB(skb)->flags & IPSKB_REROUTED));
        }

        static int ip_finish_output(struct sk_buff *skb)
        {
            printk("ip_finish_output Enter\n");

            printk("ip_finish_output ip_finish_output2\n");
            return ip_finish_output2(skb);
        }

        static inline int ip_finish_output2(struct sk_buff *skb)
        {
            if (rt->rt_type == RTN_MULTICAST) {
                IP_UPD_PO_STATS(dev_net(dev), IPSTATS_MIB_OUTMCAST, skb->len);
            } else if (rt->rt_type == RTN_BROADCAST)
                IP_UPD_PO_STATS(dev_net(dev), IPSTATS_MIB_OUTBCAST, skb->len);
            
            nexthop = (__force u32) rt_nexthop(rt, ip_hdr(skb)->daddr);
            neigh = __ipv4_neigh_lookup_noref(dev, nexthop);
            if (unlikely(!neigh)) {
                printk("ip_finish_output2 __neigh_create\n");
                neigh = __neigh_create(&arp_tbl, &nexthop, dev, false);
            }
            if (!IS_ERR(neigh)) {
                int res;
                printk("ip_finish_output2 dst_neigh_output\n");
                res = dst_neigh_output(dst, neigh, skb);

                rcu_read_unlock_bh();
                return res;
            }
        }

        static inline int dst_neigh_output(struct dst_entry *dst, struct neighbour *n,
				   struct sk_buff *skb)
        {
            printk("dst_neigh_output Enter\n");

            hh = &n->hh;
            if ((n->nud_state & NUD_CONNECTED) && hh->hh_len) {
                printk("dst_neigh_output neigh_hh_output\n");
                return neigh_hh_output(hh, skb);
            }
            else {
                printk("dst_neigh_output n->output\n");
                return n->output(n, skb);                           // 对应下面的neigh_blackhole
            }
        }
    }
-----------------------------------------------------------------------------------------
Dst.h (include\net)
->  {
        /* Output packet to network from transport.  */
        static inline int dst_output(struct sk_buff *skb)
        {
            printk("dst_output Enter\n");
            return skb_dst(skb)->output(skb);                       // 这里对应上面的dst.output, 即ip_output
        }
    }
----------------------------------------------------------------------------------------
Neighbour.h (include\net)
->  {
        static inline int neigh_hh_output(const struct hh_cache *hh, struct sk_buff *skb)
        {    
            return dev_queue_xmit(skb);
        }
    }
------------------------------------------------------------------------------------------
Dev.c (net\core)
->  {
        int dev_queue_xmit(struct sk_buff *skb)
        {
            printk("__dev_xmit_skb Enter\n");

            printk("__dev_xmit_skb sch_direct_xmit\n");
            sch_direct_xmit(skb, q, dev, txq, root_lock);
        }

        int dev_hard_start_xmit(struct sk_buff *skb, struct net_device *dev,
			struct netdev_queue *txq)
        {
            printk("dev_hard_start_xmit Enter\n");
    
            printk("dev_hard_start_xmit ndo_start_xmit\n");a                    // 调用dhd driver里面的ndo_start_xmit函数
            rc = ops->ndo_start_xmit(skb, dev);
        }
    }
-----------------------------------------------------------------------------------------
Sch_generic.c (net\sched)
->  {
        /*
         * Transmit one skb, and handle the return status as required. Holding the
         * __QDISC_STATE_RUNNING bit guarantees that only one CPU can execute this
         * function.
         *
         * Returns to the caller:
         *				0  - queue is empty or throttled.
         *				>0 - queue is not empty.
         */
        int sch_direct_xmit(struct sk_buff *skb, struct Qdisc *q,
                struct net_device *dev, struct netdev_queue *txq,
                spinlock_t *root_lock)
        {
            printk("sch_direct_xmit Enter\n");
        
            if (!netif_xmit_frozen_or_stopped(txq)) {
                printk("sch_direct_xmit netif_xmit_frozen_or_stopped\n");
                ret = dev_hard_start_xmit(skb, dev, txq);
            }
        }
    }
----------------------------------------------------------------------------------------------
Dhd_linux.c (kernel\drivers\net\wireless\bcmdhd)
->  {
        static struct net_device_ops dhd_ops_pri = {
            .ndo_open = dhd_open,
            .ndo_stop = dhd_stop,
            .ndo_get_stats = dhd_get_stats,
            .ndo_do_ioctl = dhd_ioctl_entry,
            .ndo_start_xmit = dhd_start_xmit,
            .ndo_set_mac_address = dhd_set_mac_address,
        #if (LINUX_VERSION_CODE >= KERNEL_VERSION(3, 2, 0))
            .ndo_set_rx_mode = dhd_set_multicast_list,
        #else
            .ndo_set_multicast_list = dhd_set_multicast_list,
        #endif
        };

        int dhd_register_if(dhd_pub_t *dhdp, int ifidx, bool need_rtnl_lock)
        {
            net->netdev_ops = &dhd_ops_pri;
        }

        int BCMFASTPATH dhd_start_xmit(struct sk_buff *skb, struct net_device *net)
        {
            // ... 
        }
    }

